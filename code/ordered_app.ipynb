{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LoadData**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando data desde 2019/\n",
      "Cargando data desde 2020/\n",
      "Cargando data desde 2021/\n",
      "Cargando data desde 2022/\n",
      "Cargando data desde 2023/\n",
      "Cargando data desde 2024/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "df_actual = pd.read_csv('InformationByTokenClass.csv')\n",
    "DATA_PATH = ''\n",
    "years = ['2019', '2020', '2021', '2022', '2023','2024']\n",
    "df_per_year = []\n",
    "def load_data(year):\n",
    "  folder_path = DATA_PATH + year + '/'\n",
    "  print(\"Cargando data desde \" + folder_path)\n",
    "  csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "  dfs = [pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]\n",
    "  df_per_year.append(dfs)\n",
    "\n",
    "for year in years:\n",
    "  load_data(year)\n",
    "df_per_year = [dataset for sublist in df_per_year for dataset in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "# Funci칩n para crear un dataset con los tokens presentes en el diccionario iterando en la lista de datasets\n",
    "def filter_and_combine_datasets(name, symbol, datasets):\n",
    "    filtered_dfs = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        filtered_df = dataset[(dataset['name'] == name) & (dataset['symbol'] == symbol)]\n",
    "        \n",
    "        if not filtered_df.empty:\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "    if not filtered_dfs:\n",
    "        print(f\"No se encontraron datos para {name} con s칤mbolo {symbol}.\")\n",
    "        return None\n",
    "    \n",
    "    combined_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "    combined_df = combined_df.sort_values(by='last_updated').reset_index(drop=True)\n",
    "    combined_df = combined_df.drop(columns=['maxSupply'], errors='ignore')\n",
    "    combined_df=cleanData(combined_df)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def print_high_null_columns(df, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Imprime las columnas que tienen m치s del 'threshold' de valores nulos.\n",
    "    \n",
    "    :param df: DataFrame a analizar\n",
    "    :param threshold: Umbral para detectar columnas con alto porcentaje de nulos\n",
    "    \"\"\"\n",
    "    null_percentage = df.isna().mean()\n",
    "    high_null_columns = null_percentage[null_percentage > threshold]\n",
    "\n",
    "    if not high_null_columns.empty:\n",
    "        print(\"Columnas con m치s del {:.0%} de valores nulos:\".format(threshold))\n",
    "        print(high_null_columns)\n",
    "    else:\n",
    "        print(\"Ninguna columna tiene m치s del {:.0%} de valores nulos.\".format(threshold))\n",
    "\n",
    "\n",
    "def count_nulls(df):\n",
    "  nan_counts_by_group = df.groupby('name').apply(lambda x: x.isna().sum())\n",
    "  return nan_counts_by_group\n",
    "\n",
    "def cleanData(dataset):\n",
    "    df_final = dataset.replace(0, np.nan)\n",
    "    print_high_null_columns(df_final, threshold=0.7)\n",
    "    df_final = fill_nulls(df_final)\n",
    "    return df_final\n",
    "\n",
    "def fill_nulls(df):\n",
    "    df['last_updated'] = pd.to_datetime(df['last_updated'])\n",
    "    df['dateAdded'] = pd.to_datetime(df['dateAdded'])\n",
    "    filled_data = []\n",
    "\n",
    "    for name, group in df.groupby('name'):\n",
    "        numeric_cols = ['circulatingSupply', 'volume24h', 'marketCap',\n",
    "                        'percentChange1h', 'percentChange24h', 'percentChange7d']\n",
    "        group[numeric_cols] = group[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Eliminar filas donde marketCap es NaN\n",
    "        group = group.dropna(subset=['marketCap'])\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            group[col] = group[col].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        group[numeric_cols] = group[numeric_cols].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        filled_data.append(group)\n",
    "    \n",
    "    filled_df = pd.concat(filled_data, ignore_index=True)\n",
    "    return filled_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Low Market Cap Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Name</th>\n",
       "      <th>Token</th>\n",
       "      <th>Price</th>\n",
       "      <th>One_Hour_Percentage</th>\n",
       "      <th>TwentyFour_Hour_Percentage</th>\n",
       "      <th>Seven_Days_Percentage</th>\n",
       "      <th>Market_Cap</th>\n",
       "      <th>URL</th>\n",
       "      <th>socialNetworks</th>\n",
       "      <th>...</th>\n",
       "      <th>Class</th>\n",
       "      <th>Capture_Date</th>\n",
       "      <th>halving_1_RankIndex</th>\n",
       "      <th>halving_1_plus250_RankIndex</th>\n",
       "      <th>halving_2_RankIndex</th>\n",
       "      <th>halving_2_plus250_RankIndex</th>\n",
       "      <th>halving_3_RankIndex</th>\n",
       "      <th>halving_3_plus250_RankIndex</th>\n",
       "      <th>halving_4_RankIndex</th>\n",
       "      <th>halving_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1798</td>\n",
       "      <td>Uno Re</td>\n",
       "      <td>UNO</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7.68</td>\n",
       "      <td>906638</td>\n",
       "      <td>https://coinmarketcap.com/currencies/unore/</td>\n",
       "      <td>洧뎶, Twitter, Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1811</td>\n",
       "      <td>ApeBond</td>\n",
       "      <td>ABOND</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2.20</td>\n",
       "      <td>864511</td>\n",
       "      <td>https://coinmarketcap.com/currencies/apebond/</td>\n",
       "      <td>洧뎶, Twitter, Reddit, Telegram, Chat</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1822</td>\n",
       "      <td>GoCrypto Token</td>\n",
       "      <td>GOC</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.18</td>\n",
       "      <td>819189</td>\n",
       "      <td>https://coinmarketcap.com/currencies/gocrypto-...</td>\n",
       "      <td>Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>796.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1824</td>\n",
       "      <td>Lithium</td>\n",
       "      <td>LITH</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>17.77</td>\n",
       "      <td>818201</td>\n",
       "      <td>https://coinmarketcap.com/currencies/lithium/</td>\n",
       "      <td>洧뎶, Twitter</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1856</td>\n",
       "      <td>AIgentX</td>\n",
       "      <td>AIX</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6.87</td>\n",
       "      <td>66.05</td>\n",
       "      <td>728116</td>\n",
       "      <td>https://coinmarketcap.com/currencies/aigentx/</td>\n",
       "      <td>洧뎶, Twitter, Discord, Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2732.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>5848</td>\n",
       "      <td>XTV</td>\n",
       "      <td>XTV</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.21</td>\n",
       "      <td>7.91</td>\n",
       "      <td>209988</td>\n",
       "      <td>https://coinmarketcap.com/currencies/xtv/</td>\n",
       "      <td>洧뎶, Twitter, Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>5858</td>\n",
       "      <td>Cats Of Sol</td>\n",
       "      <td>COS</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.17</td>\n",
       "      <td>79960</td>\n",
       "      <td>https://coinmarketcap.com/currencies/cats-of-sol/</td>\n",
       "      <td>洧뎶, Twitter, Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>5864</td>\n",
       "      <td>Baby Sora</td>\n",
       "      <td>BABYSORA</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.01</td>\n",
       "      <td>66.79</td>\n",
       "      <td>51903</td>\n",
       "      <td>https://coinmarketcap.com/currencies/baby-sora-/</td>\n",
       "      <td>洧뎶, Twitter, Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5324.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>5869</td>\n",
       "      <td>TieDan</td>\n",
       "      <td>TIEDAN</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.43</td>\n",
       "      <td>9.97</td>\n",
       "      <td>25.30</td>\n",
       "      <td>84636</td>\n",
       "      <td>https://coinmarketcap.com/currencies/tiedan/</td>\n",
       "      <td>洧뎶, Twitter, Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>5873</td>\n",
       "      <td>FWOG (ETH)</td>\n",
       "      <td>FWOG</td>\n",
       "      <td>0.092358</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.66</td>\n",
       "      <td>12.70</td>\n",
       "      <td>99186</td>\n",
       "      <td>https://coinmarketcap.com/currencies/fwog/</td>\n",
       "      <td>洧뎶, Twitter, Telegram</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows 칑 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ranking            Name     Token     Price  One_Hour_Percentage  \\\n",
       "156      1798          Uno Re       UNO  0.011590                 0.06   \n",
       "157      1811         ApeBond     ABOND  0.005992                 0.50   \n",
       "158      1822  GoCrypto Token       GOC  0.003340                 0.02   \n",
       "159      1824         Lithium      LITH  0.000156                 1.61   \n",
       "160      1856         AIgentX       AIX  0.009806                 0.88   \n",
       "...       ...             ...       ...       ...                  ...   \n",
       "2232     5848             XTV       XTV  0.021000                 0.00   \n",
       "2233     5858     Cats Of Sol       COS  0.000800                 0.00   \n",
       "2234     5864       Baby Sora  BABYSORA  0.012124                 0.01   \n",
       "2235     5869          TieDan    TIEDAN  0.000085                 2.43   \n",
       "2236     5873      FWOG (ETH)      FWOG  0.092358                 0.00   \n",
       "\n",
       "      TwentyFour_Hour_Percentage  Seven_Days_Percentage  Market_Cap  \\\n",
       "156                         0.06                   7.68      906638   \n",
       "157                         0.63                   2.20      864511   \n",
       "158                         4.58                   3.18      819189   \n",
       "159                         0.40                  17.77      818201   \n",
       "160                         6.87                  66.05      728116   \n",
       "...                          ...                    ...         ...   \n",
       "2232                       10.21                   7.91      209988   \n",
       "2233                        1.08                   9.17       79960   \n",
       "2234                        4.01                  66.79       51903   \n",
       "2235                        9.97                  25.30       84636   \n",
       "2236                        3.66                  12.70       99186   \n",
       "\n",
       "                                                    URL  \\\n",
       "156         https://coinmarketcap.com/currencies/unore/   \n",
       "157       https://coinmarketcap.com/currencies/apebond/   \n",
       "158   https://coinmarketcap.com/currencies/gocrypto-...   \n",
       "159       https://coinmarketcap.com/currencies/lithium/   \n",
       "160       https://coinmarketcap.com/currencies/aigentx/   \n",
       "...                                                 ...   \n",
       "2232          https://coinmarketcap.com/currencies/xtv/   \n",
       "2233  https://coinmarketcap.com/currencies/cats-of-sol/   \n",
       "2234   https://coinmarketcap.com/currencies/baby-sora-/   \n",
       "2235       https://coinmarketcap.com/currencies/tiedan/   \n",
       "2236         https://coinmarketcap.com/currencies/fwog/   \n",
       "\n",
       "                          socialNetworks  ...  Class  Capture_Date  \\\n",
       "156                 洧뎶, Twitter, Telegram  ...      0    2024-09-23   \n",
       "157   洧뎶, Twitter, Reddit, Telegram, Chat  ...      0    2024-09-23   \n",
       "158                             Telegram  ...      0    2024-09-23   \n",
       "159                           洧뎶, Twitter  ...      0    2024-09-23   \n",
       "160        洧뎶, Twitter, Discord, Telegram  ...      0    2024-09-23   \n",
       "...                                  ...  ...    ...           ...   \n",
       "2232                洧뎶, Twitter, Telegram  ...      3    2024-09-23   \n",
       "2233                洧뎶, Twitter, Telegram  ...      3    2024-09-23   \n",
       "2234                洧뎶, Twitter, Telegram  ...      3    2024-09-23   \n",
       "2235                洧뎶, Twitter, Telegram  ...      3    2024-09-23   \n",
       "2236                洧뎶, Twitter, Telegram  ...      3    2024-09-23   \n",
       "\n",
       "      halving_1_RankIndex  halving_1_plus250_RankIndex  halving_2_RankIndex  \\\n",
       "156                   NaN                          NaN                  NaN   \n",
       "157                   NaN                          NaN                  NaN   \n",
       "158                   NaN                          NaN                  NaN   \n",
       "159                   NaN                          NaN                  NaN   \n",
       "160                   NaN                          NaN                  NaN   \n",
       "...                   ...                          ...                  ...   \n",
       "2232                  NaN                          NaN                  NaN   \n",
       "2233                  NaN                          NaN                  NaN   \n",
       "2234                  NaN                          NaN                  NaN   \n",
       "2235                  NaN                          NaN                  NaN   \n",
       "2236                  NaN                          NaN                  NaN   \n",
       "\n",
       "      halving_2_plus250_RankIndex halving_3_RankIndex  \\\n",
       "156                           NaN                 NaN   \n",
       "157                           NaN                 NaN   \n",
       "158                           NaN               796.0   \n",
       "159                           NaN                 NaN   \n",
       "160                           NaN                 NaN   \n",
       "...                           ...                 ...   \n",
       "2232                          NaN                 NaN   \n",
       "2233                          NaN                 NaN   \n",
       "2234                          NaN                 NaN   \n",
       "2235                          NaN                 NaN   \n",
       "2236                          NaN                 NaN   \n",
       "\n",
       "      halving_3_plus250_RankIndex  halving_4_RankIndex  halving_survive  \n",
       "156                           NaN               1342.0                0  \n",
       "157                           NaN               1368.0                0  \n",
       "158                         650.0               1556.0                1  \n",
       "159                           NaN               1140.0                0  \n",
       "160                           NaN               2732.0                0  \n",
       "...                           ...                  ...              ...  \n",
       "2232                          NaN                  NaN                0  \n",
       "2233                          NaN               3599.0                0  \n",
       "2234                          NaN               5324.0                0  \n",
       "2235                          NaN                  NaN                0  \n",
       "2236                          NaN                  NaN                0  \n",
       "\n",
       "[1314 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_class=pd.read_csv('InformationByTokenClass.csv')\n",
    "# Filtrar las monedas cuyo market cap es de 2 millones o menos\n",
    "filtered_df = token_class[(token_class['Market_Cap'] <= 1_000_000) & (token_class['Market_Cap'] > 0)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista vac칤a para almacenar los DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Iterar sobre cada fila del dataframe filtrado\n",
    "for index, row in filtered_df.iterrows():\n",
    "    name = row['Name']\n",
    "    token = row['Token']\n",
    "    \n",
    "    # Filtrar y combinar datos usando la funci칩n proporcionada\n",
    "    combined_data = filter_and_combine_datasets(name, token, df_per_year)\n",
    "    \n",
    "    # Agregar el DataFrame combinado a la lista\n",
    "    df_list.append(combined_data)\n",
    "\n",
    "# Mostrar los primeros 5 elementos de la lista para verificar\n",
    "df_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que df_list contiene los DataFrames\n",
    "\n",
    "# Filtrar los DataFrames que no sean None y tengan 30 filas o m치s\n",
    "filtered_df_list = [df for df in df_list if df is not None and df.shape[0] >= 15]\n",
    "\n",
    "# Mostrar el n칰mero de DataFrames que cumplen la condici칩n\n",
    "print(f\"El n칰mero de datasets con 10 filas o m치s es: {len(filtered_df_list)}\")\n",
    "\n",
    "# Usar un set para almacenar el nombre y s칤mbolo de las monedas de manera 칰nica\n",
    "name_symbol_set = set()\n",
    "\n",
    "# Iterar sobre los DataFrames filtrados y extraer el nombre y s칤mbolo\n",
    "for df in filtered_df_list:\n",
    "    if 'name' in df.columns and 'symbol' in df.columns:\n",
    "        for index, row in df.iterrows():\n",
    "            # A침adir nombre y s칤mbolo al set (esto elimina duplicados autom치ticamente)\n",
    "            name_symbol_set.add((row['name'], row['symbol']))\n",
    "\n",
    "# Crear un DataFrame con los datos 칰nicos\n",
    "name_symbol_df = pd.DataFrame(list(name_symbol_set), columns=['Name', 'Symbol'])\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(name_symbol_df)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "name_symbol_df.to_csv('monedas_info_dataset.csv', index=False)\n",
    "\n",
    "print(\"Datos 칰nicos guardados en 'monedas_info_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtrar por categoria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name     Symbol  Class\n",
      "0                 Kambria        KAT      0\n",
      "1        Wrapped Dogecoin      WDOGE      3\n",
      "2                  POLKER        PKR      1\n",
      "3                  Arcona     ARCONA      0\n",
      "4    Castle of Blackwater       COBE      1\n",
      "..                    ...        ...    ...\n",
      "183               Nutcoin        NUT      3\n",
      "184              The QWAN       QWAN      1\n",
      "185               AIgentX        AIX      0\n",
      "186          KittenWifHat  KITTENWIF      3\n",
      "187            Nvidia Inu       NINU      3\n",
      "\n",
      "[188 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario con las combinaciones de 'Name' y 'Token' y su respectiva 'Class' desde filtered_df\n",
    "name_token_to_class = dict(zip(zip(filtered_df['Name'], filtered_df['Token']), filtered_df['Class']))\n",
    "\n",
    "# Agregar la columna 'Class' a name_symbol_df basada en la coincidencia de 'Name' y 'Symbol'\n",
    "name_symbol_df['Class'] = name_symbol_df.apply(\n",
    "    lambda row: name_token_to_class.get((row['Name'], row['Symbol']), None),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Mostrar el DataFrame actualizado con la columna 'Class'\n",
    "print(name_symbol_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "1    92\n",
      "3    60\n",
      "0    31\n",
      "2     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar cu치ntos de cada categor칤a hay en la columna 'Class'\n",
    "category_counts = name_symbol_df['Class'].value_counts()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(category_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Iterar por las filas de name_symbol_df\n",
    "def process_by_name_symbol(df_per_year, name_symbol_df):\n",
    "    # Estructuras para almacenar resultados y errores\n",
    "    results = []\n",
    "    errors = []\n",
    "    \n",
    "    # Iterar por cada fila de `name_symbol_df`\n",
    "    for _, row in name_symbol_df.iterrows():\n",
    "        name = row[\"Name\"]\n",
    "        token = row[\"Symbol\"]\n",
    "        class_category = row[\"Class\"]\n",
    "\n",
    "        print(f\"Procesando: Name={name}, Token={token}, Class={class_category}\")\n",
    "\n",
    "        try:\n",
    "            # Filtrar y combinar datasets\n",
    "            df_filtered = filter_and_combine_datasets(name, token, df_per_year)\n",
    "\n",
    "            if df_filtered is None or df_filtered.empty:\n",
    "                print(f\"No se encontraron datos para {name} con s칤mbolo {token}.\")\n",
    "                errors.append({\"name\": name, \"token\": token, \"error\": \"No se encontraron datos\"})\n",
    "                continue\n",
    "\n",
    "            # Realizar predicci칩n con SARIMA\n",
    "            graph_data, graph_layout, comparison_results, one_month_predict = train_sarima_and_predict(df_filtered)\n",
    "\n",
    "            # Guardar los resultados en una lista\n",
    "            results.append({\n",
    "                \"name\": name,\n",
    "                \"token\": token,\n",
    "                \"class\": class_category,\n",
    "                \"graph_data\": graph_data,\n",
    "                \"graph_layout\": graph_layout,\n",
    "                \"comparison_results\": comparison_results,\n",
    "                \"one_month_predict\": one_month_predict\n",
    "            })\n",
    "\n",
    "            print(f\"Predicci칩n completada para {name} ({token}) con 칠xito.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {name} ({token}): {str(e)}\")\n",
    "            errors.append({\"name\": name, \"token\": token, \"error\": str(e)})\n",
    "\n",
    "    # Retornar resultados y errores\n",
    "    return results, errors\n",
    "\n",
    "# Ejecuci칩n principal\n",
    "results, errors = process_by_name_symbol(df_per_year, name_symbol_df)\n",
    "\n",
    "# Manejo de resultados\n",
    "if results:\n",
    "    print(f\"Se procesaron correctamente {len(results)} monedas.\")\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Seleccionar el top 5 de cada categor칤a basado en \"one_month_predict\"\n",
    "    top_5_per_class = (\n",
    "        results_df.sort_values(by=\"one_month_predict\", ascending=False)\n",
    "        .groupby(\"class\")\n",
    "        .head(5)\n",
    "    )\n",
    "\n",
    "    # Guardar el top 5 por categor칤a en un archivo CSV\n",
    "    top_5_per_class.to_csv(\"top_5_per_class.csv\", index=False)\n",
    "    print(\"Archivo 'top_5_per_class.csv' guardado con 칠xito.\")\n",
    "\n",
    "# Manejo de errores\n",
    "if errors:\n",
    "    print(f\"Se encontraron errores en {len(errors)} monedas.\")\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    errors_df.to_csv(\"errors.csv\", index=False)\n",
    "    print(\"Archivo 'errors.csv' guardado con 칠xito.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se procesaron correctamente 153 monedas.\n",
      "Archivo 'top_5_per_class.csv' guardado con 칠xito.\n",
      "Se encontraron errores en 35 monedas.\n",
      "Archivo 'errors.csv' guardado con 칠xito.\n"
     ]
    }
   ],
   "source": [
    "# Manejo de resultados\n",
    "if results:\n",
    "    print(f\"Se procesaron correctamente {len(results)} monedas.\")\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Seleccionar el top 5 de cada categor칤a basado en \"one_month_predict\"\n",
    "    top_5_per_class = (\n",
    "        results_df.sort_values(by=\"one_month_predict\", ascending=False)\n",
    "        .groupby(\"class\")\n",
    "        .head(5)\n",
    "    )\n",
    "\n",
    "    # Guardar el top 5 por categor칤a en un archivo CSV\n",
    "    top_5_per_class.to_csv(\"top_5_per_class.csv\", index=False)\n",
    "    print(\"Archivo 'top_5_per_class.csv' guardado con 칠xito.\")\n",
    "\n",
    "# Manejo de errores\n",
    "if errors:\n",
    "    print(f\"Se encontraron errores en {len(errors)} monedas.\")\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    errors_df.to_csv(\"errors.csv\", index=False)\n",
    "    print(\"Archivo 'errors.csv' guardado con 칠xito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model, Load LigthBGM** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from skforecast.plot import set_dark_theme\n",
    "from skforecast.preprocessing import exog_long_to_dict\n",
    "\n",
    "df = pd.read_csv('df_skforecast.csv')\n",
    "forecaster = load('skforecaster_model.joblib')\n",
    "\n",
    "df['last_updated'] = pd.to_datetime(df['last_updated'])\n",
    "names = unique_names = df['name'].unique().tolist()\n",
    "\n",
    "def predictLight(name, steps_p, df):\n",
    "    # Filtrar los datos del token espec칤fico\n",
    "    df_pred = df[df['name'] == name]\n",
    "    df_pred = df_pred.sort_values(by='last_updated')\n",
    "\n",
    "    # Preparar la serie y las variables ex칩genas\n",
    "    series = df_pred[['name', 'last_updated', 'marketCap']]\n",
    "    exog = df_pred[['name', 'last_updated', 'cmcRank', 'price', 'volume24h', 'percentChange1h', 'percentChange24h']]\n",
    "\n",
    "    # Convertir las variables ex칩genas a diccionario para el modelo\n",
    "    exog_dict = exog_long_to_dict(\n",
    "        data=exog,\n",
    "        series_id='name',\n",
    "        index='last_updated',\n",
    "        freq='W'  # Frecuencia semanal\n",
    "    )\n",
    "\n",
    "    # Realizar la predicci칩n para los pr칩ximos 'steps_p' periodos\n",
    "    predicciones = forecaster.predict(steps=steps_p, exog=exog_dict, suppress_warnings=True)\n",
    "    predicciones.index = pd.date_range(start=df_pred['last_updated'].max(), periods=steps_p, freq='W')\n",
    "\n",
    "    # Filtrar las predicciones solo para el token seleccionado\n",
    "    if name in predicciones.columns:\n",
    "        predicciones = predicciones[[name]]\n",
    "    else:\n",
    "        raise ValueError(f\"No se encontraron predicciones para el token: {name}\")\n",
    "\n",
    "    # Crear la gr치fica interactiva con Plotly\n",
    "    fig = Figure()\n",
    "\n",
    "    # Graficar datos reales\n",
    "    fig.add_trace(Scatter(\n",
    "        x=series['last_updated'],\n",
    "        y=series['marketCap'],\n",
    "        mode='lines',\n",
    "        name='Real',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "\n",
    "\n",
    "    # C치lculo de los cambios porcentuales para las predicciones futuras\n",
    "    last_real_value = series['marketCap'].iloc[-1]  # 칔ltimo valor real\n",
    "    percent_changes = ((predicciones[name].values - last_real_value) / last_real_value) * 100\n",
    "\n",
    "    # Preparamos los datos de comparaci칩n futura\n",
    "    future_dates = pd.date_range(start=predicciones.index[0], periods=steps_p, freq='W')\n",
    "    future_comparison = pd.DataFrame({\n",
    "        'ds': future_dates,\n",
    "        'y_actual': ['-'] * len(future_dates),\n",
    "        'y_pred': predicciones[name].values,\n",
    "        'abs_error': ['-'] * len(future_dates),\n",
    "        'percent_error': ['-'] * len(future_dates),\n",
    "        'percent_change': percent_changes.tolist(),\n",
    "        'name': name\n",
    "    })\n",
    "\n",
    "    # Agregar la l칤nea de la predicci칩n final (predicci칩n a futuro con el modelo completo)\n",
    "    fig.add_trace(Scatter(\n",
    "        x=future_dates,\n",
    "        y=predicciones[name].values,\n",
    "        mode='lines',\n",
    "        name='Prediction',\n",
    "        line=dict(color='#d1a800', width=2)\n",
    "    ))\n",
    "\n",
    "    # Personalizar el dise침o del gr치fico\n",
    "    fig.update_layout(\n",
    "        title=f'Comparaci칩n Predicci칩n vs Real para {name}',\n",
    "        xaxis_title='Fecha',\n",
    "        yaxis_title='Market Cap',\n",
    "        legend_title='Tipo',\n",
    "        template='plotly_white',\n",
    "        xaxis=dict(tickformat='%Y-%m-%d')  # Formato para que solo aparezca la fecha (sin hora)\n",
    "    )\n",
    "\n",
    "    # Convertir los datos a formatos serializables para JSON\n",
    "    graph_data = [trace.to_plotly_json() for trace in fig.data]\n",
    "    graph_layout = fig.layout.to_plotly_json()\n",
    "\n",
    "    # Convertir todos los objetos de numpy a listas\n",
    "    comparison_results = future_comparison.to_dict(orient='records')\n",
    "\n",
    "    # Serializar los datos\n",
    "    graph_data_serializable = convert_to_serializable(graph_data)\n",
    "    graph_layout_serializable = convert_to_serializable(graph_layout)\n",
    "    comparison_results_serializable = convert_to_serializable(comparison_results)\n",
    "\n",
    "    # Calcular el cambio porcentual para la predicci칩n a 1 mes\n",
    "    one_month_predict = percent_changes[3] if len(percent_changes) > 3 else 0.0\n",
    "\n",
    "    return graph_data_serializable, graph_layout_serializable, comparison_results_serializable, one_month_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pmdarima import auto_arima\n",
    "from plotly.graph_objects import Scatter, Figure\n",
    "from plotly.offline import plot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from flask_cors import CORS\n",
    "\n",
    "# Crear la app de Flask\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "# Funci칩n para dividir los datos en entrenamiento y prueba\n",
    "def split_data_by_date(df, train_size=0.8):\n",
    "    df_sorted = df.sort_values(by='ds')\n",
    "    cutoff_index = int(len(df_sorted) * train_size)\n",
    "    train_data = df_sorted[:cutoff_index]\n",
    "    test_data = df_sorted[cutoff_index:]\n",
    "    return train_data, test_data\n",
    "\n",
    "# Funci칩n para determinar si la serie temporal tiene suficiente longitud para capturar estacionalidad\n",
    "def get_seasonality(df):\n",
    "    if len(df) < 12:  # Menos de 12 puntos de datos, no se considera estacionalidad\n",
    "        return False\n",
    "    return True  # Para m치s de 12 puntos de datos, se considera estacionalidad\n",
    "\n",
    "# Funci칩n para convertir NaN a None y ndarray a list\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"Convierte NaN a None y ndarray a list para ser serializado a JSON\"\"\"\n",
    "    if isinstance(obj, float) and (obj != obj):  # Verifica NaN (NaN != NaN)\n",
    "        return None\n",
    "    elif isinstance(obj, np.ndarray):  # Convierte ndarray a lista\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "def train_sarima_and_predict(df, future_months=3, prediction_interval='7D'):\n",
    "    # Agrupar por fecha y calcular el promedio de marketCap\n",
    "    df_grouped = df.groupby(['name', 'last_updated']).agg({\n",
    "        'marketCap': 'mean',\n",
    "        'price': 'mean',\n",
    "        'volume24h': 'mean',\n",
    "        'cmcRank': 'mean',\n",
    "        'percentChange1h': 'mean',\n",
    "        'percentChange24h': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    df_grouped.rename(columns={'last_updated': 'ds', 'marketCap': 'y'}, inplace=True)\n",
    "\n",
    "    # Verificar si hay valores nulos antes de aplicar el escalado\n",
    "    exogenous_features = ['price', 'volume24h', 'cmcRank', 'percentChange1h', 'percentChange24h']\n",
    "    missing_columns = df_grouped[exogenous_features].isnull().sum()\n",
    "    if missing_columns.any():\n",
    "        return jsonify({\"error\": f\"Faltan valores en las columnas: {', '.join(missing_columns[missing_columns > 0].index)}\"}), 400\n",
    "\n",
    "    # Verificar si la serie temporal (y) tiene nulos\n",
    "    if df_grouped['y'].isnull().sum() > 0:\n",
    "        return jsonify({\"error\": \"Faltan valores en la columna 'y' (marketCap).\"}), 400\n",
    "\n",
    "    # Aplicar transformaci칩n logar칤tmica para estabilizar la varianza\n",
    "    df_grouped['y'] = np.log1p(df_grouped['y'])\n",
    "\n",
    "    # Escalar las variables ex칩genas\n",
    "    scaler = StandardScaler()\n",
    "    df_grouped[exogenous_features] = scaler.fit_transform(df_grouped[exogenous_features])\n",
    "\n",
    "    # Dividir los datos en entrenamiento y prueba (80% - 20%)\n",
    "    train_size = int(len(df_grouped) * 0.8)\n",
    "    train_data = df_grouped[:train_size]\n",
    "    test_data = df_grouped[train_size:]\n",
    "\n",
    "    # Verificar si tenemos datos suficientes para realizar el modelado\n",
    "    if len(test_data) == 0:\n",
    "        return jsonify({\"error\": \"No hay suficientes datos en el conjunto de prueba para realizar las predicciones.\"}), 400\n",
    "\n",
    "    # Determinar si se debe usar estacionalidad dependiendo del tama침o de los datos\n",
    "    seasonal_flag = get_seasonality(train_data)\n",
    "\n",
    "    # Optimizar los par치metros con auto_arima\n",
    "    model_auto = auto_arima(\n",
    "        train_data['y'], \n",
    "        exogenous=train_data[exogenous_features], \n",
    "        seasonal=seasonal_flag,\n",
    "        m=12 if seasonal_flag else 1,\n",
    "        stepwise=True, \n",
    "        trace=True\n",
    "    )\n",
    "    print(model_auto.summary())\n",
    "\n",
    "    # Ajustar el modelo SARIMA con los mejores par치metros encontrados\n",
    "    model = SARIMAX(\n",
    "        train_data['y'],\n",
    "        exog=train_data[exogenous_features],\n",
    "        order=model_auto.order,\n",
    "        seasonal_order=model_auto.seasonal_order if seasonal_flag else (0, 0, 0, 0),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    model_fit = model.fit(disp=False)\n",
    "\n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    test_forecast = model_fit.get_forecast(steps=len(test_data), exog=test_data[exogenous_features])\n",
    "    y_pred = np.expm1(test_forecast.predicted_mean)  # Revertir transformaci칩n logar칤tmica\n",
    "\n",
    "    # Calcular MAE y RMSE\n",
    "    y_test_actual = np.expm1(test_data['y'])\n",
    "    mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred))\n",
    "    print(f\"Mean Absolute Error (Prueba): {mae}\")\n",
    "    print(f\"Root Mean Squared Error (Prueba): {rmse}\")\n",
    "\n",
    "    # Crear DataFrame de comparaci칩n\n",
    "    comparison = pd.DataFrame({\n",
    "        'ds': test_data['ds'],\n",
    "        'y_actual': y_test_actual.tolist(),\n",
    "        'y_pred': y_pred.tolist(),\n",
    "        'abs_error': abs(y_test_actual - y_pred).tolist(),\n",
    "        'percent_error': ((abs(y_test_actual - y_pred) / y_test_actual) * 100).tolist(),\n",
    "        'name': df['name'].iloc[0]\n",
    "    })\n",
    "    \n",
    "    # Aseg칰rate de que el n칰mero de pasos futuros sea el correcto\n",
    "    future_steps = (future_months * 4)  # Aproximadamente 3 meses (12 semanas)\n",
    "\n",
    "    # Verifica si tienes suficientes pasos para la predicci칩n\n",
    "    if len(test_data) >= future_steps:\n",
    "        # Si tienes suficiente longitud en los datos de prueba, usa los ex칩genos directamente\n",
    "        exog_futuro = test_data[exogenous_features].iloc[-future_steps:]\n",
    "    else:\n",
    "        # Si no tienes suficiente longitud, usa el 칰ltimo valor disponible y rep칤telo para completar los pasos necesarios\n",
    "        exog_futuro = pd.DataFrame(np.tile(test_data[exogenous_features].iloc[-1].values, (future_steps, 1)),\n",
    "                                columns=exogenous_features)\n",
    "\n",
    "    # Aseg칰rate de que las dimensiones de los ex칩genos futuros sean correctas\n",
    "    if exog_futuro.shape[0] != future_steps:\n",
    "        return jsonify({\"error\": f\"El n칰mero de pasos futuros no coincide con los ex칩genos.\"}), 400\n",
    "\n",
    "    # Generar la predicci칩n para los pasos futuros con los ex칩genos correctos\n",
    "    future_forecast = model_fit.get_forecast(steps=future_steps, exog=exog_futuro)\n",
    "\n",
    "    # Generar fechas futuras\n",
    "    future_dates = pd.date_range(start=test_data['ds'].max(), periods=future_steps + 1, freq=prediction_interval)[1:]\n",
    "\n",
    "    # Predicciones futuras\n",
    "    future_predictions = np.expm1(future_forecast.predicted_mean)\n",
    "\n",
    "    # Calcular el percentChange basado en el 칰ltimo valor real\n",
    "    last_real_value = y_test_actual.iloc[-1]  # 칔ltimo valor real\n",
    "\n",
    "\n",
    "\n",
    "    # Crear la gr치fica interactiva con Plotly\n",
    "    fig = Figure()\n",
    "\n",
    "    # Graficar datos reales (todas las fechas reales de entrenamiento + prueba)\n",
    "    all_real_data = pd.concat([train_data[['ds', 'y']], test_data[['ds', 'y']]], ignore_index=True)\n",
    "    fig.add_trace(Scatter(x=all_real_data['ds'], y=np.expm1(all_real_data['y']), mode='lines', name='Real', line=dict(color='blue')))\n",
    "\n",
    "    # Graficar las predicciones solo desde el inicio del conjunto de prueba\n",
    "    fig.add_trace(Scatter(x=comparison['ds'], y=comparison['y_pred'], mode='lines', name='Predicci칩n', line=dict(color='red', dash='dash')))\n",
    "\n",
    "    # Graficar el modelo entrenado con todo el conjunto de datos\n",
    "    model_all_data = SARIMAX(\n",
    "        df_grouped['y'],\n",
    "        exog=df_grouped[exogenous_features],\n",
    "        order=model_auto.order,\n",
    "        seasonal_order=model_auto.seasonal_order if seasonal_flag else (0, 0, 0, 0),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    model_all_fit = model_all_data.fit(disp=False)\n",
    "    all_forecast = model_all_fit.get_forecast(steps=future_steps, exog=exog_futuro)\n",
    "    future_predictions_all = np.expm1(all_forecast.predicted_mean)\n",
    "\n",
    "\n",
    "    percent_changes = ((future_predictions_all - last_real_value) / last_real_value) * 100\n",
    "\n",
    "    one_month_predict = 0.0\n",
    "    # Imprimir el percentChange para las predicciones futuras\n",
    "    for i, percent_change in enumerate(percent_changes):\n",
    "        print(f\"Percent Change para la predicci칩n futura {i+1} ({future_dates[i]}): {percent_change:.2f}%\")\n",
    "        if i == 3:\n",
    "            one_month_predict = percent_change\n",
    "\n",
    "\n",
    "        # Crear DataFrame con las predicciones futuras\n",
    "    future_comparison = pd.DataFrame({\n",
    "        'ds': future_dates,\n",
    "        'y_actual': ['-'] * len(future_dates),\n",
    "        'y_pred': [\n",
    "            future_predictions_all.tolist()[i] if '-' == '-' else future_predictions[i]\n",
    "            for i in range(len(future_dates))\n",
    "        ],\n",
    "        'abs_error': ['-'] * len(future_dates),\n",
    "        'percent_error': ['-'] * len(future_dates),  # No calcular el error porcentual en las predicciones futuras\n",
    "        'percent_change': percent_changes.tolist(),  # Incluir percent_change en las predicciones futuras\n",
    "        'name': df['name'].iloc[0]\n",
    "    })\n",
    "    # Unir los resultados de la comparaci칩n\n",
    "    comparison = pd.concat([comparison, future_comparison], ignore_index=True)\n",
    "\n",
    "    # Agregar la l칤nea amarilla (modelo entrenado con todo el conjunto de datos) con un tono m치s oscuro\n",
    "    fig.add_trace(Scatter(x=future_dates, y=future_predictions_all, mode='lines', name='Prediction(Train+Test)', line=dict(color='#d1a800', width=2)))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Comparaci칩n Predicci칩n vs Real para {df[\"name\"].iloc[0]}',\n",
    "        xaxis_title='Fecha',\n",
    "        yaxis_title='Market Cap',\n",
    "        legend_title='Tipo',\n",
    "        template='plotly_white',\n",
    "        xaxis=dict(\n",
    "            tickformat='%Y-%m-%d'  # Formato para que solo aparezca la fecha (sin hora)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Serializar datos y layout para JSON\n",
    "    graph_data = [trace.to_plotly_json() for trace in fig.data]\n",
    "    graph_layout = fig.layout.to_plotly_json()\n",
    "\n",
    "    # Convertir todos los objetos de numpy a listas\n",
    "    comparison_results = comparison.to_dict(orient='records')\n",
    "\n",
    "    # Convertir todo a estructuras serializables para JSON\n",
    "    graph_data_serializable = convert_to_serializable(graph_data)\n",
    "    graph_layout_serializable = convert_to_serializable(graph_layout)\n",
    "    comparison_results_serializable = convert_to_serializable(comparison_results)\n",
    "    print(one_month_predict)\n",
    "    # Ahora `comparison_results_serializable` contiene el `percent_change`\n",
    "    return graph_data_serializable, graph_layout_serializable, comparison_results_serializable, one_month_predict\n",
    "\n",
    "# Rutas de Flask\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return \"Bienvenido al servidor Flask!\"\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "\n",
    "        if 'name' not in data or 'symbol' not in data:\n",
    "            return jsonify({\"error\": \"Faltan par치metros 'name' o 'symbol'\"}), 400\n",
    "\n",
    "        name = data['name']\n",
    "        symbol = data['symbol']\n",
    "        print(f\"Recibidos: name={name}, symbol={symbol}\")\n",
    "\n",
    "        # Aqu칤 deber칤as tener el DataFrame `df_per_year`\n",
    "        df_final = filter_and_combine_datasets(name, symbol, df_per_year)\n",
    "\n",
    "        if df_final is None or df_final.empty:\n",
    "            return jsonify({\"error\": f\"No se encontraron datos para {name} con s칤mbolo {symbol}.\"}), 404\n",
    "\n",
    "        # Preparar los datos\n",
    "        df_final['last_updated'] = pd.to_datetime(df_final['last_updated'], errors='coerce')\n",
    "\n",
    "        # Generar predicciones y obtener datos para la gr치fica\n",
    "        graph_data, graph_layout, comparison_results,one_month_predict = train_sarima_and_predict(df_final)\n",
    "\n",
    "        return jsonify({\n",
    "            \"graph_data\": graph_data,  # Datos de la gr치fica serializados\n",
    "            \"graph_layout\": graph_layout,  # Layout de la gr치fica serializado\n",
    "            \"comparison_results\": comparison_results,# Resultados de comparaci칩n\n",
    "            \"one_month_predict\": one_month_predict  # Predicci칩n para un mes  \n",
    "        }), 200\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {str(e)}\")\n",
    "        return jsonify({\"error\": f\"Error inesperado: {str(e)}\"}), 500\n",
    "\n",
    "\n",
    "@app.route('/top_5_per_class', methods=['GET'])\n",
    "def get_top_5_per_class():\n",
    "    try:\n",
    "        # Ruta del archivo CSV\n",
    "        file_path = 'top_5_per_class.csv'\n",
    "\n",
    "        # Verificar si el archivo existe\n",
    "        if not os.path.exists(file_path):\n",
    "            return jsonify({\"error\": f\"El archivo {file_path} no se encuentra.\"}), 404\n",
    "\n",
    "        # Leer el archivo CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Convertir a JSON\n",
    "        data_json = df.to_dict(orient='records')\n",
    "\n",
    "        return jsonify(data_json), 200\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo: {str(e)}\")\n",
    "        return jsonify({\"error\": f\"Error inesperado: {str(e)}\"}), 500\n",
    "\n",
    "\n",
    "@app.route('/predict-l', methods=['POST'])\n",
    "def approute():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        namecoin = data['name']\n",
    "        df = pd.read_csv('df_skforecast.csv')\n",
    "        df['last_updated'] = pd.to_datetime(df['last_updated'], errors='coerce')\n",
    "\n",
    "        \n",
    "        graph_data, graph_layout, comparison_results, one_month_predict = predictLight(namecoin, 30, df)\n",
    "\n",
    "\n",
    "        response = {\n",
    "            'graph_data': graph_data,\n",
    "            'graph_layout': graph_layout,\n",
    "            'comparison_results': comparison_results,\n",
    "            'one_month_predict': one_month_predict\n",
    "        }\n",
    "\n",
    "        return jsonify(response)\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "\n",
    "# Ejecutar Flask\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False, port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
